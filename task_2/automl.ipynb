{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"./data/\")\n",
    "RS = 3984765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153417, 27)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(DATA_DIR.joinpath(\"train.parquet\"))\n",
    "print(train_df.shape)\n",
    "index_split = int(train_df.shape[0] * 0.8)\n",
    "test_df = train_df[index_split:]\n",
    "train_df = train_df[:index_split]\n",
    "test_df.shape\n",
    "\n",
    "train_f = train_df.drop([\"target0\", \"target1\"], axis=1)\n",
    "test_f = test_df.drop([\"target0\", \"target1\"], axis=1)\n",
    "\n",
    "train_l = train_df[[\"target0\", \"target1\"]]\n",
    "test_l = test_df[[\"target0\", \"target1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/preprocessing/tabular_preprocessing/feature_preprocessing/Nystroem.py:130: UserWarning: Given choices for `score_func` are not compatible with the dataset. Updating choices to ['poly', 'rbf', 'sigmoid', 'cosine']\n",
      "  warnings.warn(f\"Given choices for `score_func` are not compatible with the dataset. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] [2023-06-01 20:48:54,136:Client-AutoPyTorch:2fe963c3-009c-11ee-a903-847b572ad870:1] Prediction for lgb failed with run state StatusType.CRASHED.\n",
      "Additional info:\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/tae.py\", line 61, in fit_predict_try_except_decorator\n",
      "    ta(queue=queue, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 512, in eval_train_function\n",
      "    evaluator.fit_predict_and_loss()\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 186, in fit_predict_and_loss\n",
      "    y_train_pred, y_opt_pred, y_valid_pred, y_test_pred = self._fit_and_predict(pipeline, split_id,\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 364, in _fit_and_predict\n",
      "    fit_and_suppress_warnings(self.logger, pipeline, X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/abstract_evaluator.py\", line 339, in fit_and_suppress_warnings\n",
      "    pipeline.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/abstract_evaluator.py\", line 181, in fit\n",
      "    return self.pipeline.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/base_pipeline.py\", line 155, in fit\n",
      "    self.fit_estimator(X, y, **fit_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/base_pipeline.py\", line 174, in fit_estimator\n",
      "    self._final_estimator.fit(X, y, **fit_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/base_choice.py\", line 217, in fit\n",
      "    return self.choice.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/base_model.py\", line 98, in fit\n",
      "    self.fit_output = self.model.fit(X['X_train'][X['train_indices']], X['y_train'][X['train_indices']],\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/traditional_learner/base_traditional_learner.py\", line 184, in fit\n",
      "    self._fit(X_train, y_train, X_val, y_val)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/traditional_learner/learners.py\", line 69, in _fit\n",
      "    self.model.fit(X_train, y_train, eval_set=eval_set)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 658, in fit\n",
      "    _X, _y = _LGBMCheckXY(X, y, accept_sparse=True, force_all_finite=False, ensure_min_samples=2)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 883, in check_X_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (82231, 2) instead.\n",
      "\n",
      "error: ValueError('y should be a 1d array, got an array of shape (82231, 2) instead.')\n",
      "configuration_origin: traditional\n",
      "[ERROR] [2023-06-01 20:48:54,436:Client-AutoPyTorch:2fe963c3-009c-11ee-a903-847b572ad870:1] Prediction for catboost failed with run state StatusType.CRASHED.\n",
      "Additional info:\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/tae.py\", line 61, in fit_predict_try_except_decorator\n",
      "    ta(queue=queue, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 512, in eval_train_function\n",
      "    evaluator.fit_predict_and_loss()\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 186, in fit_predict_and_loss\n",
      "    y_train_pred, y_opt_pred, y_valid_pred, y_test_pred = self._fit_and_predict(pipeline, split_id,\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 364, in _fit_and_predict\n",
      "    fit_and_suppress_warnings(self.logger, pipeline, X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/abstract_evaluator.py\", line 339, in fit_and_suppress_warnings\n",
      "    pipeline.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/abstract_evaluator.py\", line 181, in fit\n",
      "    return self.pipeline.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/base_pipeline.py\", line 155, in fit\n",
      "    self.fit_estimator(X, y, **fit_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/base_pipeline.py\", line 174, in fit_estimator\n",
      "    self._final_estimator.fit(X, y, **fit_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/base_choice.py\", line 217, in fit\n",
      "    return self.choice.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/base_model.py\", line 98, in fit\n",
      "    self.fit_output = self.model.fit(X['X_train'][X['train_indices']], X['y_train'][X['train_indices']],\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/traditional_learner/base_traditional_learner.py\", line 182, in fit\n",
      "    self._prepare_model(X_train, y_train)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/traditional_learner/learners.py\", line 123, in _prepare_model\n",
      "    self.config['eval_metric'] = AutoPyTorchToCatboostMetrics[self.metric.name].value\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/enum.py\", line 440, in __getitem__\n",
      "    return cls._member_map_[name]\n",
      "KeyError: 'mean_squared_error'\n",
      "\n",
      "error: KeyError('mean_squared_error')\n",
      "configuration_origin: traditional\n",
      "[ERROR] [2023-06-01 20:48:57,469:Client-AutoPyTorch:2fe963c3-009c-11ee-a903-847b572ad870:1] Prediction for random_forest failed with run state StatusType.MEMOUT.\n",
      "Additional info:\n",
      "error: Memout (used more than 4096 MB).\n",
      "configuration_origin: traditional\n",
      "[ERROR] [2023-06-01 20:48:59,008:Client-AutoPyTorch:2fe963c3-009c-11ee-a903-847b572ad870:1] Prediction for extra_trees failed with run state StatusType.MEMOUT.\n",
      "Additional info:\n",
      "error: Memout (used more than 4096 MB).\n",
      "configuration_origin: traditional\n",
      "[ERROR] [2023-06-01 20:48:59,307:Client-AutoPyTorch:2fe963c3-009c-11ee-a903-847b572ad870:1] Prediction for svm failed with run state StatusType.CRASHED.\n",
      "Additional info:\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/tae.py\", line 61, in fit_predict_try_except_decorator\n",
      "    ta(queue=queue, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 512, in eval_train_function\n",
      "    evaluator.fit_predict_and_loss()\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 186, in fit_predict_and_loss\n",
      "    y_train_pred, y_opt_pred, y_valid_pred, y_test_pred = self._fit_and_predict(pipeline, split_id,\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/train_evaluator.py\", line 364, in _fit_and_predict\n",
      "    fit_and_suppress_warnings(self.logger, pipeline, X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/abstract_evaluator.py\", line 339, in fit_and_suppress_warnings\n",
      "    pipeline.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/evaluation/abstract_evaluator.py\", line 181, in fit\n",
      "    return self.pipeline.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/base_pipeline.py\", line 155, in fit\n",
      "    self.fit_estimator(X, y, **fit_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/base_pipeline.py\", line 174, in fit_estimator\n",
      "    self._final_estimator.fit(X, y, **fit_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/base_choice.py\", line 217, in fit\n",
      "    return self.choice.fit(X, y)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/base_model.py\", line 98, in fit\n",
      "    self.fit_output = self.model.fit(X['X_train'][X['train_indices']], X['y_train'][X['train_indices']],\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/traditional_learner/base_traditional_learner.py\", line 184, in fit\n",
      "    self._fit(X_train, y_train, X_val, y_val)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/pipeline/components/setup/traditional_ml/traditional_learner/learners.py\", line 364, in _fit\n",
      "    self.model.fit(X_train, y_train)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 883, in check_X_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (82231, 2) instead.\n",
      "\n",
      "error: ValueError('y should be a 1d array, got an array of shape (82231, 2) instead.')\n",
      "configuration_origin: traditional\n",
      "[ERROR] [2023-06-01 20:49:00,613:Client-AutoPyTorch:2fe963c3-009c-11ee-a903-847b572ad870:1] Prediction for knn failed with run state StatusType.MEMOUT.\n",
      "Additional info:\n",
      "error: Memout (used more than 4096 MB).\n",
      "configuration_origin: traditional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/intensification/parallel_scheduling.py:154: UserWarning: Hyperband is executed with 1 workers only. Consider to use pynisher to use all available workers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautoPyTorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtabular_regression\u001b[39;00m \u001b[39mimport\u001b[39;00m TabularRegressionTask \u001b[39mas\u001b[39;00m TRT\n\u001b[1;32m      3\u001b[0m api \u001b[39m=\u001b[39m TRT(n_threads\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m api\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m      6\u001b[0m     X_train\u001b[39m=\u001b[39;49mtrain_f,\n\u001b[1;32m      7\u001b[0m     y_train\u001b[39m=\u001b[39;49mtrain_l,\n\u001b[1;32m      8\u001b[0m     X_test\u001b[39m=\u001b[39;49mtest_f,\n\u001b[1;32m      9\u001b[0m     y_test\u001b[39m=\u001b[39;49mtest_l,\n\u001b[1;32m     10\u001b[0m     optimize_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     total_walltime_limit\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     func_eval_time_limit_secs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/api/tabular_regression.py:451\u001b[0m, in \u001b[0;36mTabularRegressionTask.search\u001b[0;34m(self, optimize_metric, X_train, y_train, X_test, y_test, dataset_name, feat_types, budget_type, min_budget, max_budget, total_walltime_limit, func_eval_time_limit_secs, enable_traditional_pipeline, memory_limit, smac_scenario_args, get_smac_object_callback, all_supported_metrics, precision, disable_file_output, load_models, portfolio_selection, dataset_compression)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_compression \u001b[39m=\u001b[39m get_dataset_compression_mapping(memory_limit, dataset_compression)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_validator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_dataset_input_validator(\n\u001b[1;32m    441\u001b[0m     X_train\u001b[39m=\u001b[39mX_train,\n\u001b[1;32m    442\u001b[0m     y_train\u001b[39m=\u001b[39my_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m     dataset_compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_compression,\n\u001b[1;32m    449\u001b[0m     feat_types\u001b[39m=\u001b[39mfeat_types)\n\u001b[0;32m--> 451\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_search(\n\u001b[1;32m    452\u001b[0m     dataset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset,\n\u001b[1;32m    453\u001b[0m     optimize_metric\u001b[39m=\u001b[39;49moptimize_metric,\n\u001b[1;32m    454\u001b[0m     budget_type\u001b[39m=\u001b[39;49mbudget_type,\n\u001b[1;32m    455\u001b[0m     min_budget\u001b[39m=\u001b[39;49mmin_budget,\n\u001b[1;32m    456\u001b[0m     max_budget\u001b[39m=\u001b[39;49mmax_budget,\n\u001b[1;32m    457\u001b[0m     total_walltime_limit\u001b[39m=\u001b[39;49mtotal_walltime_limit,\n\u001b[1;32m    458\u001b[0m     func_eval_time_limit_secs\u001b[39m=\u001b[39;49mfunc_eval_time_limit_secs,\n\u001b[1;32m    459\u001b[0m     enable_traditional_pipeline\u001b[39m=\u001b[39;49menable_traditional_pipeline,\n\u001b[1;32m    460\u001b[0m     memory_limit\u001b[39m=\u001b[39;49mmemory_limit,\n\u001b[1;32m    461\u001b[0m     smac_scenario_args\u001b[39m=\u001b[39;49msmac_scenario_args,\n\u001b[1;32m    462\u001b[0m     get_smac_object_callback\u001b[39m=\u001b[39;49mget_smac_object_callback,\n\u001b[1;32m    463\u001b[0m     all_supported_metrics\u001b[39m=\u001b[39;49mall_supported_metrics,\n\u001b[1;32m    464\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    465\u001b[0m     disable_file_output\u001b[39m=\u001b[39;49mdisable_file_output,\n\u001b[1;32m    466\u001b[0m     load_models\u001b[39m=\u001b[39;49mload_models,\n\u001b[1;32m    467\u001b[0m     portfolio_selection\u001b[39m=\u001b[39;49mportfolio_selection,\n\u001b[1;32m    468\u001b[0m )\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/api/base_task.py:1218\u001b[0m, in \u001b[0;36mBaseTask._search\u001b[0;34m(self, optimize_metric, dataset, budget_type, min_budget, max_budget, total_walltime_limit, func_eval_time_limit_secs, enable_traditional_pipeline, memory_limit, smac_scenario_args, get_smac_object_callback, tae_func, all_supported_metrics, precision, disable_file_output, load_models, portfolio_selection, dask_client, **kwargs)\u001b[0m\n\u001b[1;32m   1184\u001b[0m _proc_smac \u001b[39m=\u001b[39m AutoMLSMBO(\n\u001b[1;32m   1185\u001b[0m     config_space\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_space,\n\u001b[1;32m   1186\u001b[0m     dataset_name\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(dataset\u001b[39m.\u001b[39mdataset_name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1215\u001b[0m )\n\u001b[1;32m   1216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m     run_history, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results_manager\u001b[39m.\u001b[39mtrajectory, budget_type \u001b[39m=\u001b[39m \\\n\u001b[0;32m-> 1218\u001b[0m         _proc_smac\u001b[39m.\u001b[39;49mrun_smbo(func\u001b[39m=\u001b[39;49mtae_func)\n\u001b[1;32m   1219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_history\u001b[39m.\u001b[39mupdate(run_history, DataOrigin\u001b[39m.\u001b[39mINTERNAL)\n\u001b[1;32m   1220\u001b[0m     trajectory_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m   1221\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mget_smac_output_directory_for_run(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed),\n\u001b[1;32m   1222\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrajectory.json\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/autoPyTorch/optimizer/smbo.py:414\u001b[0m, in \u001b[0;36mAutoMLSMBO.run_smbo\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    410\u001b[0m     smac\u001b[39m.\u001b[39mregister_callback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble_callback)\n\u001b[1;32m    412\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39minitialised SMBO, running SMBO.optimize()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 414\u001b[0m smac\u001b[39m.\u001b[39;49moptimize()\n\u001b[1;32m    416\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mfinished SMBO.optimize()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunhistory \u001b[39m=\u001b[39m smac\u001b[39m.\u001b[39msolver\u001b[39m.\u001b[39mrunhistory\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/facade/smac_ac_facade.py:723\u001b[0m, in \u001b[0;36mSMAC4AC.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m incumbent \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m     incumbent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    724\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    725\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/smbo.py:229\u001b[0m, in \u001b[0;36mSMBO.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    227\u001b[0m \u001b[39m# sample next configuration for intensification\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m# Initial design runs are also included in the BO loop now.\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m intent, run_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintensifier\u001b[39m.\u001b[39;49mget_next_run(\n\u001b[1;32m    230\u001b[0m     challengers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_design_configs,\n\u001b[1;32m    231\u001b[0m     incumbent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mincumbent,\n\u001b[1;32m    232\u001b[0m     chooser\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepm_chooser,\n\u001b[1;32m    233\u001b[0m     run_history\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunhistory,\n\u001b[1;32m    234\u001b[0m     repeat_configs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintensifier\u001b[39m.\u001b[39;49mrepeat_configs,\n\u001b[1;32m    235\u001b[0m     num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtae_runner\u001b[39m.\u001b[39;49mnum_workers(),\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[39m# remove config from initial design challengers to not repeat it again\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_design_configs \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_design_configs \u001b[39mif\u001b[39;00m c \u001b[39m!=\u001b[39m run_info\u001b[39m.\u001b[39mconfig]\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/intensification/parallel_scheduling.py:169\u001b[0m, in \u001b[0;36mParallelScheduler.get_next_run\u001b[0;34m(self, challengers, incumbent, chooser, run_history, repeat_configs, num_workers)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m# First get a config to run from a SH instance\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_instances_by_stage(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintensifier_instances):\n\u001b[0;32m--> 169\u001b[0m     intent, run_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintensifier_instances[i]\u001b[39m.\u001b[39;49mget_next_run(\n\u001b[1;32m    170\u001b[0m         challengers\u001b[39m=\u001b[39;49mchallengers,\n\u001b[1;32m    171\u001b[0m         incumbent\u001b[39m=\u001b[39;49mincumbent,\n\u001b[1;32m    172\u001b[0m         chooser\u001b[39m=\u001b[39;49mchooser,\n\u001b[1;32m    173\u001b[0m         run_history\u001b[39m=\u001b[39;49mrun_history,\n\u001b[1;32m    174\u001b[0m         repeat_configs\u001b[39m=\u001b[39;49mrepeat_configs,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    177\u001b[0m     \u001b[39m# if asked to wait, the intensifier cannot come up\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[39m# with a new configuration, so we continue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m intent \u001b[39m==\u001b[39m RunInfoIntent\u001b[39m.\u001b[39mWAIT:\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/intensification/hyperband.py:236\u001b[0m, in \u001b[0;36m_Hyperband.get_next_run\u001b[0;34m(self, challengers, incumbent, chooser, run_history, repeat_configs, num_workers)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39m# sampling from next challenger marks the beginning of a new iteration\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miteration_done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m intent, run_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msh_intensifier\u001b[39m.\u001b[39;49mget_next_run(\n\u001b[1;32m    237\u001b[0m     challengers\u001b[39m=\u001b[39;49mchallengers,\n\u001b[1;32m    238\u001b[0m     incumbent\u001b[39m=\u001b[39;49mincumbent,\n\u001b[1;32m    239\u001b[0m     chooser\u001b[39m=\u001b[39;49mchooser,\n\u001b[1;32m    240\u001b[0m     run_history\u001b[39m=\u001b[39;49mrun_history,\n\u001b[1;32m    241\u001b[0m     repeat_configs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msh_intensifier\u001b[39m.\u001b[39;49mrepeat_configs,\n\u001b[1;32m    242\u001b[0m )\n\u001b[1;32m    244\u001b[0m \u001b[39m# For testing purposes, this attribute highlights whether a\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# new challenger is proposed or not. Not required from a functional\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# perspective\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_challenger \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msh_intensifier\u001b[39m.\u001b[39mnew_challenger\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/intensification/successive_halving.py:570\u001b[0m, in \u001b[0;36m_SuccessiveHalving.get_next_run\u001b[0;34m(self, challengers, incumbent, chooser, run_history, repeat_configs, num_workers)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    567\u001b[0m     \u001b[39m# select next configuration\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    569\u001b[0m         \u001b[39m# first stage, so sample from configurations/chooser provided\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m         challenger \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_challenger(\n\u001b[1;32m    571\u001b[0m             challengers\u001b[39m=\u001b[39;49mchallengers,\n\u001b[1;32m    572\u001b[0m             chooser\u001b[39m=\u001b[39;49mchooser,\n\u001b[1;32m    573\u001b[0m             run_history\u001b[39m=\u001b[39;49mrun_history,\n\u001b[1;32m    574\u001b[0m             repeat_configs\u001b[39m=\u001b[39;49mrepeat_configs,\n\u001b[1;32m    575\u001b[0m         )\n\u001b[1;32m    576\u001b[0m         \u001b[39mif\u001b[39;00m challenger \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    577\u001b[0m             \u001b[39m# If no challenger was sampled from the EPM or\u001b[39;00m\n\u001b[1;32m    578\u001b[0m             \u001b[39m# initial challengers, it might mean that the EPM\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[39m# None if the proposed config us already in the run history\u001b[39;00m\n\u001b[1;32m    582\u001b[0m             \u001b[39m# To get a new config, we wait for more data\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[39mreturn\u001b[39;00m RunInfoIntent\u001b[39m.\u001b[39mWAIT, RunInfo(\n\u001b[1;32m    584\u001b[0m                 config\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    585\u001b[0m                 instance\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m                 source_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39midentifier,\n\u001b[1;32m    592\u001b[0m             )\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/intensification/abstract_racer.py:254\u001b[0m, in \u001b[0;36mAbstractRacer._next_challenger\u001b[0;34m(self, challengers, chooser, run_history, repeat_configs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39m# select challenger from the generators\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39massert\u001b[39;00m chall_gen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m \u001b[39mfor\u001b[39;00m challenger \u001b[39min\u001b[39;00m chall_gen:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# repetitions allowed\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m repeat_configs:\n\u001b[1;32m    257\u001b[0m         \u001b[39mreturn\u001b[39;00m challenger\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/maximizer.py:858\u001b[0m, in \u001b[0;36mChallengerList.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchallengers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 858\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchallengers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchallengers_callback()\n\u001b[1;32m    859\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchallengers[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index]\n\u001b[1;32m    860\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/maximizer.py:98\u001b[0m, in \u001b[0;36mAcquisitionFunctionMaximizer.maximize.<locals>.next_configs_by_acq_value\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext_configs_by_acq_value\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Configuration]:\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m [t[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maximize(runhistory, stats, num_points)]\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/maximizer.py:668\u001b[0m, in \u001b[0;36mLocalAndSortedRandomSearch._maximize\u001b[0;34m(self, runhistory, stats, num_points)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maximize\u001b[39m(\n\u001b[1;32m    661\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    662\u001b[0m     runhistory: RunHistory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m \n\u001b[1;32m    667\u001b[0m     \u001b[39m# Get configurations sorted by EI\u001b[39;00m\n\u001b[0;32m--> 668\u001b[0m     next_configs_by_random_search_sorted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_search\u001b[39m.\u001b[39;49m_maximize(\n\u001b[1;32m    669\u001b[0m         runhistory,\n\u001b[1;32m    670\u001b[0m         stats,\n\u001b[1;32m    671\u001b[0m         num_points,\n\u001b[1;32m    672\u001b[0m         _sorted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    673\u001b[0m     )\n\u001b[1;32m    675\u001b[0m     next_configs_by_local_search \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_search\u001b[39m.\u001b[39m_maximize(\n\u001b[1;32m    676\u001b[0m         runhistory,\n\u001b[1;32m    677\u001b[0m         stats,\n\u001b[1;32m    678\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sls_iterations,\n\u001b[1;32m    679\u001b[0m         additional_start_points\u001b[39m=\u001b[39mnext_configs_by_random_search_sorted,\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    682\u001b[0m     \u001b[39m# Having the configurations from random search, sorted by their\u001b[39;00m\n\u001b[1;32m    683\u001b[0m     \u001b[39m# acquisition function value is important for the first few iterations\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     \u001b[39m# of SMAC. As long as the random forest predicts constant value, we\u001b[39;00m\n\u001b[1;32m    685\u001b[0m     \u001b[39m# want to use only random configurations. Having them at the begging of\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[39m# the list ensures this (even after adding the configurations by local\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[39m# search, and then sorting them)\u001b[39;00m\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/maximizer.py:607\u001b[0m, in \u001b[0;36mRandomSearch._maximize\u001b[0;34m(self, runhistory, stats, num_points, _sorted)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(rand_configs)):\n\u001b[1;32m    606\u001b[0m         rand_configs[i]\u001b[39m.\u001b[39morigin \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRandom Search (sorted)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 607\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sort_configs_by_acq_value(rand_configs)\n\u001b[1;32m    608\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    609\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(rand_configs)):\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/maximizer.py:148\u001b[0m, in \u001b[0;36mAcquisitionFunctionMaximizer._sort_configs_by_acq_value\u001b[0;34m(self, configs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sort_configs_by_acq_value\u001b[39m(\u001b[39mself\u001b[39m, configs: List[Configuration]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mfloat\u001b[39m, Configuration]]:\n\u001b[1;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sort the given configurations by acquisition value.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m            ordered by their acquisition function value\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     acq_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49macquisition_function(configs)\n\u001b[1;32m    150\u001b[0m     \u001b[39m# From here\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[39m# http://stackoverflow.com/questions/20197990/how-to-make-argsort-result-to-be-random-between-equal-values\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     random \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrng\u001b[39m.\u001b[39mrand(\u001b[39mlen\u001b[39m(acq_values))\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/__init__.py:81\u001b[0m, in \u001b[0;36mAbstractAcquisitionFunction.__call__\u001b[0;34m(self, configurations)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     79\u001b[0m     X \u001b[39m=\u001b[39m X[np\u001b[39m.\u001b[39mnewaxis, :]\n\u001b[0;32m---> 81\u001b[0m acq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute(X)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(acq)):\n\u001b[1;32m     83\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(np\u001b[39m.\u001b[39misnan(acq))[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/optimizer/acquisition/__init__.py:389\u001b[0m, in \u001b[0;36mEI._compute\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    387\u001b[0m     X \u001b[39m=\u001b[39m X[:, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[0;32m--> 389\u001b[0m m, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_marginalized_over_instances(X)\n\u001b[1;32m    390\u001b[0m s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(v)\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meta \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/epm/random_forest/rf_with_instances.py:284\u001b[0m, in \u001b[0;36mRandomForestWithInstances.predict_marginalized_over_instances\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict mean and variance marginalized over all instances.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[1;32m    260\u001b[0m \u001b[39mReturns the predictive mean and variance marginalised over all\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m    Predictive variance\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_features \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_features) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     mean_, var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    285\u001b[0m     \u001b[39massert\u001b[39;00m var \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# please mypy\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     var[var \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_threshold] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_threshold\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/epm/base_epm.py:219\u001b[0m, in \u001b[0;36mBaseEPM.predict\u001b[0;34m(self, X, cov_return_type)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    218\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPredicted variances smaller than 0. Setting those variances to 0.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 219\u001b[0m     mean, var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X, cov_return_type)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mean\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    222\u001b[0m     mean \u001b[39m=\u001b[39m mean\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/smac/epm/random_forest/rf_with_instances.py:248\u001b[0m, in \u001b[0;36mRandomForestWithInstances._predict\u001b[0;34m(self, X, cov_return_type)\u001b[0m\n\u001b[1;32m    246\u001b[0m means, vars_ \u001b[39m=\u001b[39m [], []\n\u001b[1;32m    247\u001b[0m \u001b[39mfor\u001b[39;00m row_X \u001b[39min\u001b[39;00m X:\n\u001b[0;32m--> 248\u001b[0m     mean_, var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrf\u001b[39m.\u001b[39;49mpredict_mean_var(row_X)\n\u001b[1;32m    249\u001b[0m     means\u001b[39m.\u001b[39mappend(mean_)\n\u001b[1;32m    250\u001b[0m     vars_\u001b[39m.\u001b[39mappend(var)\n",
      "File \u001b[0;32m/media/thornail/LinuxOther/anaconda3/envs/ML2/lib/python3.10/site-packages/pyrfr/regression.py:2668\u001b[0m, in \u001b[0;36mbinary_rss_forest.predict_mean_var\u001b[0;34m(self, feature_vector, weighted_data)\u001b[0m\n\u001b[1;32m   2661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_mean_var\u001b[39m(\u001b[39mself\u001b[39m, feature_vector: \u001b[39m\"\u001b[39m\u001b[39mnum_vector\u001b[39m\u001b[39m\"\u001b[39m, weighted_data: \u001b[39m\"\u001b[39m\u001b[39mbool\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstd::pair< double,double >\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2662\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2663\u001b[0m \n\u001b[1;32m   2664\u001b[0m \u001b[39m    `predict_mean_var(const std::vector< num_t > &feature_vector, bool\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m \u001b[39m        weighted_data=false) -> std::pair< num_t, num_t >`  \u001b[39;00m\n\u001b[1;32m   2666\u001b[0m \n\u001b[1;32m   2667\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2668\u001b[0m     \u001b[39mreturn\u001b[39;00m _regression\u001b[39m.\u001b[39;49mbinary_rss_forest_predict_mean_var(\u001b[39mself\u001b[39;49m, feature_vector, weighted_data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from autoPyTorch.api.tabular_regression import TabularRegressionTask as TRT\n",
    "\n",
    "api = TRT(n_threads=10)\n",
    "\n",
    "api.search(\n",
    "    X_train=train_f,\n",
    "    y_train=train_l,\n",
    "    X_test=test_f,\n",
    "    y_test=test_l,\n",
    "    optimize_metric='mean_squared_error',\n",
    "    total_walltime_limit=600,\n",
    "    func_eval_time_limit_secs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.081232866117345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "pred_l = api.predict(test_f)\n",
    "\n",
    "print(mape(test_l, pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.28090286, 22.21458054],\n",
       "       [46.28090286, 22.21458054],\n",
       "       [46.28090286, 22.21458054],\n",
       "       ...,\n",
       "       [46.28090286, 22.21458054],\n",
       "       [46.28090286, 22.21458054],\n",
       "       [46.28090286, 22.21458054]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
